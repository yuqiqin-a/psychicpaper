---
{"dg-publish":true,"permalink":"/D-Source/统计和展示单词真题词频的问题-57uf/","created":"2022-07-22T15:23:55.000+08:00","updated":"2022-07-22T15:23:55.000+08:00"}
---

# 统计和展示单词真题词频的问题
最近在做考研词频和真题例句相关的工作，其实之前写的《[[D-Source/使用NLTK统计真题词频以及搜索真题句子\|使用NLTK统计真题词频以及搜索真题句子]]》这篇博客就已经记录了简单、可复现的民用实现方法，商用级别的实现提需求给开发就好了。虽然知道简易的解决方案，但是实际应用到产品中还有各种各样的问题。

## 如何计算词频
一般来说，在统计词频的时候应当把单词变形（inflection）统计在内，如plays、played和playing不应当单独计数，而统计在play上。

通常这样的问题会采用词型还原（[lemmatization](http://en.wikipedia.org/wiki/Lemmatisation)）或是词干还原（stemming）的方式解决。

词型还原和词干还原的区别在于，词型还原会考虑单词的词性，而词干还原仅会参照字典将单词还原成词干形式，例如：
> lemmatize('meeting', 'n') = meeting
> 
> lemmatize('meeting', 'v') = meet
> 
> stem('meeting') = meet

因此，词型还原更适合用在需要判断语境的词频计算中。

> "I was meeting a girl."
> 
> "There was a meeting yesterday."
> 
> {'meet': 1, 'meeting': 1}

对于名词与动名词，在词型还原的时候，程序会查询字典，如果程序能在字典中查到名词的条目，则会将lemma归为该名词条目；如果查不到，则会还原成动词，例如：

> "When our time of mourning is over, we press forward."
> 
> mourning -> mourning
> 
> "I am looking forward to listening to to you song."
> 
> listening -> listen

同理，对于派生词，因为派生词自己也在字典中拥有条目，所以也不会出现promotion、promotional还原成promote这样的情况，造成错误统计。

## 友商的解决情况

以某翻译软件为例，大部分词频与我自己写的脚本一致，但是多试几个词，还是会发现很多细节不同之处的。

例如isolate，在2010-2022年的真题中直接使用PDF阅读器搜索能找到如下内容：
> 1.（2014年英语一）...but opponents of change among the regulators insist that keeping outsiders out of a law firm **isolates** lawyers from the pressure to make money rather than serve clients ethically.
> 
> 2.（2016年英语一）\[A\] **isolated**
> 
> 3.（2012年英语二）Companies had won patents for **isolated** DNA for decades...
>
>4.（2012年英语二）In October the Department of Justice filed a brief in the Myriad case, arguing that an **isolated** DNA molecule is no less a product of nature... 
>
> 5.（2015年英语二）No matter how **isolated** you might feel and how serious the situation is, you should always remember that you are not alone.
> 
> 6.（2021年英语一）\[B\] **isolated**

该软件提示isolate在考研中出现了3次，分别是句子1、句子3和句子4。

因为isolated存在形容词这一条目，使用NLTK分词不仅会将isolated标记为形容词，而且将词频统计在isolated上。

但是查阅字典后发现，isolated形容词有三个意思，每一个都与句中用法对应不上——一个是“far away from other places”，另一个是“having minimal contact or little in common with others”，还有一个是“ single; exceptional”，因此可以判断，isolated在讲DNA的两句中是被动分词，采用的是动词“obtain or extract (a compound, microorganism, etc.) in a pure form”的生化专业释义。

这个案例的启示是：不使用神经网络的模型做词频统计，还是会有边缘案例出现，NLTK等其他库只能解决一部分的问题。

宇宙的尽头仍然是数据标注以及人工校对。

## 产品经理的想法与现实

对于统计词频这件事情，负责这个项目的产品经理们似乎有不同的意见，这也是本篇开头提到的问题。

对于考纲词mourn，无论是NLTK还是友商的软件均判定其为零频词，但是检索真题PDF文档之后发现，2015年英语二有这样的一句话：
> When our time of **mourning** is over, we press forward, stronger with a greater understanding and respect for life.

根据NLTK的判断标准，mourning在字典中有条目，因此在词型还原的过程中不会被还原成mourn，并且mourning除了有“默哀”的意思外，还有“丧服”的意思。

我认为比较合理的统计方法是与友商们的一致，mourn计为0，mourning计为1，互不打搅，泾渭分明。即便需要提示mourning，也可以在页面某处给出这个mourning这个派生词的相关信息。

![s5x27.png](https://s1.328888.xyz/2022/06/22/s5x27.png)

但是我们有一个产品同事认为：
1. 产品另做提示效果不好；
2. 词频的作用是提示单词是否重要，如果只给mourn = 0，学生会认为mourn不重要，因此错过mourning的学习，但其实mourn和mourning应该放在一起学；
3. 用户并不在意词频是对是错，不会深究词频是1还是2；
4. 就算有用户发现mourning不是动名词，而是名词，或者发现全世界的统计方法都是mourn = 0，我们是mourn = 1，我们也可以解释为计算方法不同；
5. 考纲词提示零频词过多，学习体验不好

并且ta还认为为了帮助学习，对于implement这样的词，implemtation和implemental等派生词，如果考试出现过也应该一并统计在词频中。

我对此持反对意见。

首先不是所有的词都可以这样学习，容易顾此失彼，例如exception和exceptional意思完全不一样。如果使用机器统计词频之后，还需要人工审核，这不是徒增工作量吗？

另外，目前成熟的分词工具均不支持派生词，如果需要统计派生词需要手写许多规则来判断单词关系，增加系统的复杂程度。而且这一层关系判断，只存在于拼写，没法通过词性和释义判断。

我和一个后端工程师同事做了一个demo尝试达到产品的要求，通过手写规则来推倒派生词。

经过实际测试，使用这种统计方法所“消灭”的考研零频词数量甚至不到200个，但是付出的代价却是惨痛的：
1. quart把quarter加了进来
2. integral把integrate和integrity也加了进来
3. inn把inner加了进来
4. beer有上千条记录，仅仅因为满足了be+er这一条规则
5. ...

无论如何，就目前来看，我对统计和展示词频的态度仍旧是实事求是，使用词型还原的方式进行统计。
